{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 案例2: 构建自己的多层感知机: MNIST 手写数字识别\n",
    "\n",
    "### 本案例要求如下\n",
    "- #### 实现SGD优化器 (`./optimizer.py`)\n",
    "- #### 实现全连接层FCLayer前向和后向计算 (`layers/fc_layer.py`)\n",
    "- #### 实现激活层SigmoidLayer前向和后向计算 (`layers/sigmoid_layer.py`)\n",
    "- #### 实现激活层ReLULayer前向和后向计算 (`layers/relu_layer.py`)\n",
    "- #### 实现损失层EuclideanLossLayer (`criterion/euclidean_loss.py`)\n",
    "- #### 实现损失层SoftmaxCrossEntropyLossLayer (`criterion/softmax_cross_entropy.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T02:54:09.649470Z",
     "start_time": "2023-11-10T02:54:04.279573Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "from network import Network\n",
    "from solver import train, test\n",
    "from plot import plot_loss_and_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T02:54:10.848241Z",
     "start_time": "2023-11-10T02:54:10.615415Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T02:54:10.867701Z",
     "start_time": "2023-11-10T02:54:10.863692Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_image(image):\n",
    "    # 归一化处理\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.reshape(image, [784])\n",
    "    image = image / 255.0\n",
    "    image = image - tf.reduce_mean(image)\n",
    "    return image\n",
    "\n",
    "def decode_label(label):\n",
    "    # 将标签变为one-hot编码\n",
    "    return tf.one_hot(label, depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T02:54:11.204453Z",
     "start_time": "2023-11-10T02:54:10.962291Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "x_train = tf.data.Dataset.from_tensor_slices(x_train).map(decode_image)\n",
    "y_train = tf.data.Dataset.from_tensor_slices(y_train).map(decode_label)\n",
    "data_train = tf.data.Dataset.zip((x_train, y_train))\n",
    "\n",
    "x_test = tf.data.Dataset.from_tensor_slices(x_test).map(decode_image)\n",
    "y_test = tf.data.Dataset.from_tensor_slices(y_test).map(decode_label)\n",
    "data_test = tf.data.Dataset.zip((x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T02:54:11.320413Z",
     "start_time": "2023-11-10T02:54:11.314800Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "max_epoch = 20\n",
    "init_std = 0.01\n",
    "\n",
    "learning_rate_SGD = 0.001\n",
    "weight_decay = 0.1\n",
    "\n",
    "disp_freq = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 使用欧式距离损失训练多层感知机(MLP with Euclidean Loss)\n",
    "第一部分将使用欧式距离损失训练多层感知机. \n",
    "分别使用**Sigmoid**激活函数和**ReLU**激活函数.\n",
    "### TODO\n",
    "执行以下代码之前，请完成 **./optimizer.py** 和 **criterion/euclidean_loss.py**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T02:54:11.702736Z",
     "start_time": "2023-11-10T02:54:11.690259Z"
    }
   },
   "outputs": [],
   "source": [
    "from criterion import EuclideanLossLayer\n",
    "from optimizer import SGD\n",
    "\n",
    "criterion = EuclideanLossLayer()\n",
    "\n",
    "sgd = SGD(learning_rate_SGD, weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 使用欧式距离损失和Sigmoid激活函数训练多层感知机\n",
    "训练带有一个隐含层且神经元个数为128的多层感知机，使用欧式距离损失和Sigmoid激活函数.\n",
    "\n",
    "### TODO\n",
    "执行以下代码之前，请完成 **layers/fc_layer.py** 和 **layers/sigmoid_layer.py**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T02:54:12.048086Z",
     "start_time": "2023-11-10T02:54:12.028833Z"
    }
   },
   "outputs": [],
   "source": [
    "from layers import FCLayer, SigmoidLayer\n",
    "\n",
    "sigmoidMLP = Network()\n",
    "# 使用FCLayer和SigmoidLayer构建多层感知机\n",
    "# 128为隐含层的神经元数目\n",
    "sigmoidMLP.add(FCLayer(784, 128))\n",
    "sigmoidMLP.add(SigmoidLayer())\n",
    "sigmoidMLP.add(FCLayer(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T02:54:27.016606Z",
     "start_time": "2023-11-10T02:54:12.198676Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\31393\\Desktop\\实验二\\mlp\\solver.py:15: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EuclideanLossLayer' object has no attribute 'logit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sigmoidMLP, sigmoid_loss, sigmoid_acc \u001b[38;5;241m=\u001b[39m train(sigmoidMLP, criterion, sgd, data_train, max_epoch, batch_size, disp_freq)\n",
      "File \u001b[1;32m~\\Desktop\\实验二\\mlp\\solver.py:35\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, criterion, optimizer, dataset, max_epoch, batch_size, disp_freq)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Training process\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_epoch):\n\u001b[1;32m---> 35\u001b[0m \tbatch_train_loss, batch_train_acc \u001b[38;5;241m=\u001b[39m train_one_epoch(model, criterion, optimizer, train_get_next,\n\u001b[0;32m     36\u001b[0m \t                                                    max_epoch, batch_size, disp_freq, epoch, sess)\n\u001b[0;32m     37\u001b[0m \tbatch_val_loss, batch_val_acc \u001b[38;5;241m=\u001b[39m validate(model, criterion, valid_get_next, batch_size, sess)\n\u001b[0;32m     39\u001b[0m \tavg_train_acc\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(batch_train_acc))\n",
      "File \u001b[1;32m~\\Desktop\\实验二\\mlp\\solver.py:70\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, criterion, optimizer, data_get_next, max_epoch, batch_size, disp_freq, epoch, sess)\u001b[0m\n\u001b[0;32m     67\u001b[0m criterion\u001b[38;5;241m.\u001b[39mforward(logit, train_y)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m delta \u001b[38;5;241m=\u001b[39m criterion\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     71\u001b[0m model\u001b[38;5;241m.\u001b[39mbackward(delta)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Update weights, see optimize.py\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\实验二\\mlp\\criterion\\euclidean_loss.py:27\u001b[0m, in \u001b[0;36mEuclideanLossLayer.backward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# 计算并返回梯度，梯度是logit和gt之间的差\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogit \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgt) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogit\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gradient\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'EuclideanLossLayer' object has no attribute 'logit'"
     ]
    }
   ],
   "source": [
    "sigmoidMLP, sigmoid_loss, sigmoid_acc = train(sigmoidMLP, criterion, sgd, data_train, max_epoch, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T02:54:27.019106Z",
     "start_time": "2023-11-10T02:54:27.019106Z"
    }
   },
   "outputs": [],
   "source": [
    "test(sigmoidMLP, criterion, data_test, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 使用欧式距离损失和ReLU激活函数训练多层感知机\n",
    "训练带有一个隐含层且神经元个数为128的多层感知机，使用欧式距离损失和ReLU激活函数.\n",
    "\n",
    "### TODO\n",
    "执行以下代码之前，请完成 **layers/relu_layer.py**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T02:54:27.019106Z",
     "start_time": "2023-11-10T02:54:27.019106Z"
    }
   },
   "outputs": [],
   "source": [
    "from layers import ReLULayer\n",
    "\n",
    "reluMLP = Network()\n",
    "# 使用FCLayer和ReLULayer构建多层感知机\n",
    "reluMLP.add(FCLayer(784, 128))\n",
    "reluMLP.add(ReLULayer())\n",
    "reluMLP.add(FCLayer(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T02:54:27.025301Z",
     "start_time": "2023-11-10T02:54:27.025301Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reluMLP, relu_loss, relu_acc = train(reluMLP, criterion, sgd, data_train, max_epoch, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T02:54:27.025301Z",
     "start_time": "2023-11-10T02:54:27.025301Z"
    }
   },
   "outputs": [],
   "source": [
    "test(reluMLP, criterion, data_test, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T02:54:27.028751Z",
     "start_time": "2023-11-10T02:54:27.028751Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_loss_and_acc({'Sigmoid': [sigmoid_loss, sigmoid_acc],\n",
    "                   'relu': [relu_loss, relu_acc]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 使用Softmax交叉熵损失训练多层感知机(MLP with Softmax Cross-Entropy Loss)\n",
    "第二部分将使用Softmax交叉熵损失训练多层感知机. \n",
    "分别使用**Sigmoid**激活函数和**ReLU**激活函数.\n",
    "\n",
    "### TODO\n",
    "执行以下代码之前，请完成 **criterion/softmax_cross_entropy_loss.py**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from criterion import SoftmaxCrossEntropyLossLayer\n",
    "\n",
    "criterion = SoftmaxCrossEntropyLossLayer()\n",
    "\n",
    "sgd = SGD(learning_rate_SGD, weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 使用Softmax交叉熵损失和Sigmoid激活函数训练多层感知机\n",
    "训练带有一个隐含层且神经元个数为128的多层感知机，使用Softmax交叉熵损失和Sigmoid激活函数."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoidMLP = Network()\n",
    "# 使用FCLayer和SigmoidLayer构建多层感知机\n",
    "# 128为隐含层的神经元数目\n",
    "sigmoidMLP.add(FCLayer(784, 128))\n",
    "sigmoidMLP.add(SigmoidLayer())\n",
    "sigmoidMLP.add(FCLayer(128, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sigmoidMLP, sigmoid_loss, sigmoid_acc = train(sigmoidMLP, criterion, sgd, data_train, max_epoch, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(sigmoidMLP, criterion, data_test, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 使用Softmax交叉熵损失和ReLU激活函数训练多层感知机\n",
    "训练带有一个隐含层且神经元个数为128的多层感知机，使用Softmax交叉熵损失和ReLU激活函数."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reluMLP = Network()\n",
    "# 使用FCLayer和SigmoidLayer构建多层感知机\n",
    "# 128为隐含层的神经元数目\n",
    "reluMLP.add(FCLayer(784, 128))\n",
    "reluMLP.add(ReLULayer())\n",
    "reluMLP.add(FCLayer(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reluMLP, relu_loss, relu_acc = train(reluMLP, criterion, sgd, data_train, max_epoch, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(reluMLP, criterion, data_test, batch_size, disp_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_and_acc({'Sigmoid': [sigmoid_loss, sigmoid_acc],\n",
    "                   'relu': [relu_loss, relu_acc]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 具有两层隐含层的多层感知机\n",
    "\n",
    "接下来，根据案例要求，还需要完成**构造具有两个隐含层的多层感知机，自行选取合适的激活函数和损失函数，与只有一个隐含层的结果相比较**.\n",
    "\n",
    "注意: 请在下方插入新的代码块，不要直接修改上面的代码."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
